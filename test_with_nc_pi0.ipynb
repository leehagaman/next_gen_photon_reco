{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from particle import Particle # https://github.com/scikit-hep/particle\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco BEE link: https://www.phy.bnl.gov/twister/bee/set/f51043f3-10d4-49b3-9866-bc7fbcf5d4fe/event/list/\n",
    "# truth BEE link: https://www.phy.bnl.gov/twister/bee/set/7ad1b4aa-a181-435a-9117-d37c0c9ca677/event/list/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def fps_sampling(points, n_samples):\n",
    "    \"\"\"\n",
    "    Perform Farthest Point Sampling on the input point cloud.\n",
    "    \n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points to sample\n",
    "    :return: indices of sampled points\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    sampled_indices = np.zeros(n_samples, dtype=int)\n",
    "    distances = np.full(N, np.inf)\n",
    "    \n",
    "    # Randomly choose the first point\n",
    "    sampled_indices[0] = np.random.randint(N)\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        distances = np.minimum(distances, np.sum((points - points[sampled_indices[i-1]])**2, axis=1))\n",
    "        sampled_indices[i] = np.argmax(distances)\n",
    "    \n",
    "    return sampled_indices\n",
    "\n",
    "def fps_clustering_downsample(points, n_samples):\n",
    "    \"\"\"\n",
    "    Downsample the point cloud using FPS and clustering.\n",
    "    \n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points in the downsampled cloud\n",
    "    :return: downsampled point cloud\n",
    "    \"\"\"\n",
    "    # Perform FPS to get initial samples\n",
    "    sampled_indices = fps_sampling(points, n_samples)\n",
    "    sampled_points = points[sampled_indices]\n",
    "    \n",
    "    # Use K-means clustering to associate other points with the samples\n",
    "    kmeans = KMeans(n_clusters=n_samples, init=sampled_points, n_init=1, max_iter=100)\n",
    "    kmeans.fit(points)\n",
    "    \n",
    "    # Compute the new point positions as the mean of each cluster\n",
    "    new_points = np.array([points[kmeans.labels_ == i].mean(axis=0) for i in range(n_samples)])\n",
    "    \n",
    "    return new_points\n",
    "\n",
    "def get_min_dists(points_A, points_B):\n",
    "    \"\"\"\n",
    "    Get the minimum distance between each point in points_A and all the points in points_B.\n",
    "    \"\"\"\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(points_B)\n",
    "    distances, _ = nbrs.kneighbors(points_A)\n",
    "    return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f03f9451d7d04ddfa2d61f870ff609be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the right truth event!\n"
     ]
    }
   ],
   "source": [
    "# loading event 13779 223 11160 from json truth file\n",
    "\n",
    "for dir in tqdm(os.listdir(\"input_files/misclustering_candidate_truth_outputs/bee/data/\")):\n",
    "    json_file = f\"input_files/misclustering_candidate_truth_outputs/bee/data/{dir}/{dir}-truthDepo.json\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        truth_data = json.load(f)\n",
    "\n",
    "    run = int(truth_data[\"runNo\"])\n",
    "    subrun = int(truth_data[\"subRunNo\"])\n",
    "    event = int(truth_data[\"eventNo\"])\n",
    "    \n",
    "    if run == 13779 and subrun == 223 and event == 11160:\n",
    "        print(\"found the right truth event!\")\n",
    "        break\n",
    "\n",
    "truth_spacepoints = np.column_stack((np.array(truth_data[\"x\"]) + 2, np.array(truth_data[\"y\"]), np.array(truth_data[\"z\"])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292dc3b5cdf9490cb2d0e71fa9f7ae35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the right reco event!\n"
     ]
    }
   ],
   "source": [
    "# loading event 13779 223 11160 from reco file\n",
    "\n",
    "reco_dfs = []\n",
    "\n",
    "for file in tqdm(os.listdir(\"input_files/misclustering_candidate_nue_files\")):\n",
    "    if not file.endswith(\".root\"):\n",
    "        continue\n",
    "\n",
    "    f = uproot.open(f\"input_files/misclustering_candidate_nue_files/{file}\")\n",
    "\n",
    "    rse_df = f[\"Trun\"].arrays([\"runNo\", \"subRunNo\", \"eventNo\"], library=\"pd\")\n",
    "\n",
    "    if rse_df[\"runNo\"].iloc[0] == 13779 and rse_df[\"subRunNo\"].iloc[0] == 223 and rse_df[\"eventNo\"].iloc[0] == 11160:\n",
    "        print(\"found the right reco event!\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling cosmic spacepoints...done\n",
      "calculating minimum distances...done\n"
     ]
    }
   ],
   "source": [
    "track_shower_spacepoints_df = f[\"T_rec\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "nu_trajectory_spacepoints_blob_df = f[\"T_rec_charge_blob\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "cosmic_spacepoints_df = f[\"T_cluster\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "\n",
    "cosmic_spacepoints_xyz = np.column_stack((cosmic_spacepoints_df[\"x\"], cosmic_spacepoints_df[\"y\"], cosmic_spacepoints_df[\"z\"]))\n",
    "print(\"downsampling cosmic spacepoints...\", end=\"\")\n",
    "downsampled_cosmic_spacepoints = fps_clustering_downsample(cosmic_spacepoints_xyz, 5000)\n",
    "print(\"done\")\n",
    "\n",
    "downsampled_cosmic_spacepoints_df = pd.DataFrame(downsampled_cosmic_spacepoints, columns=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "print(\"calculating minimum distances...\", end=\"\")\n",
    "min_dists = get_min_dists(downsampled_cosmic_spacepoints, truth_spacepoints)\n",
    "print(\"done\")\n",
    "\n",
    "downsampled_cosmic_spacepoints_df[\"min_dist\"] = min_dists\n",
    "\n",
    "close_to_truth_downsampled_cosmic_spacepoints_df = downsampled_cosmic_spacepoints_df[downsampled_cosmic_spacepoints_df[\"min_dist\"] <= 5.0]\n",
    "far_from_truth_downsampled_cosmic_spacepoints_df = downsampled_cosmic_spacepoints_df[downsampled_cosmic_spacepoints_df[\"min_dist\"] > 5.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scene'}]])\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=truth_spacepoints[:, 2],\n",
    "    y=truth_spacepoints[:, 0],\n",
    "    z=truth_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='orange', opacity=0.8),\n",
    "    name='BEE Truth Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=nu_trajectory_spacepoints_blob_df[\"z\"],\n",
    "    y=nu_trajectory_spacepoints_blob_df[\"x\"],\n",
    "    z=nu_trajectory_spacepoints_blob_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=nu_trajectory_spacepoints_blob_df[\"q\"],\n",
    "        colorscale='Jet',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Neutrino Cluster Spacepoints'\n",
    "))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=cosmic_spacepoints_df[\"z\"],\n",
    "    y=cosmic_spacepoints_df[\"x\"],\n",
    "    z=cosmic_spacepoints_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color='black',\n",
    "        opacity=0.5\n",
    "    ),\n",
    "    name='Cosmic Spacepoints'\n",
    "))\n",
    "\"\"\"\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=close_to_truth_downsampled_cosmic_spacepoints_df[\"z\"],\n",
    "    y=close_to_truth_downsampled_cosmic_spacepoints_df[\"x\"],\n",
    "    z=close_to_truth_downsampled_cosmic_spacepoints_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='red',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Downsampled Cosmic Spacepoints, close to truth depositions'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=far_from_truth_downsampled_cosmic_spacepoints_df[\"z\"],\n",
    "    y=far_from_truth_downsampled_cosmic_spacepoints_df[\"x\"],\n",
    "    z=far_from_truth_downsampled_cosmic_spacepoints_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='blue',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Downsampled Cosmic Spacepoints, far from truth depositions'\n",
    "))\n",
    "\n",
    "tpc_min_x = -1.\n",
    "tpc_max_x = 254.3\n",
    "tpc_min_y = -115.\n",
    "tpc_max_y = 117.\n",
    "tpc_min_z = 0.6\n",
    "tpc_max_z = 1036.4\n",
    "\n",
    "# First do the layout without camera settings\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='z',\n",
    "        yaxis_title='x',\n",
    "        zaxis_title='y',\n",
    "        aspectmode=\"auto\",\n",
    "        aspectratio=dict(\n",
    "            x=(tpc_max_z - tpc_min_z),\n",
    "            y=(tpc_max_x - tpc_min_x),\n",
    "            z=(tpc_max_y - tpc_min_y)\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            range=[tpc_min_z, tpc_max_z],\n",
    "            autorange=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[tpc_min_x, tpc_max_x],\n",
    "            autorange=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            range=[tpc_min_y, tpc_max_y],\n",
    "            autorange=False\n",
    "        )\n",
    "    ),\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    autosize=False\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
