{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from particle import Particle # https://github.com/scikit-hep/particle\n",
    "\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reco BEE link: https://www.phy.bnl.gov/twister/bee/set/f51043f3-10d4-49b3-9866-bc7fbcf5d4fe/event/list/\n",
    "# truth BEE link: https://www.phy.bnl.gov/twister/bee/set/7ad1b4aa-a181-435a-9117-d37c0c9ca677/event/list/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def fps_sampling(points, n_samples):\n",
    "    \"\"\"\n",
    "    Perform Farthest Point Sampling on the input point cloud.\n",
    "    \n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points to sample\n",
    "    :return: indices of sampled points\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    sampled_indices = np.zeros(n_samples, dtype=int)\n",
    "    distances = np.full(N, np.inf)\n",
    "    \n",
    "    # Randomly choose the first point\n",
    "    sampled_indices[0] = np.random.randint(N)\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        distances = np.minimum(distances, np.sum((points - points[sampled_indices[i-1]])**2, axis=1))\n",
    "        sampled_indices[i] = np.argmax(distances)\n",
    "    \n",
    "    return sampled_indices\n",
    "\n",
    "def fps_clustering_downsample(points, n_samples):\n",
    "    \"\"\"\n",
    "    Downsample the point cloud using FPS and clustering.\n",
    "    \n",
    "    :param points: numpy array of shape (N, 3) representing the point cloud\n",
    "    :param n_samples: number of points in the downsampled cloud\n",
    "    :return: downsampled point cloud\n",
    "    \"\"\"\n",
    "    # Perform FPS to get initial samples\n",
    "    sampled_indices = fps_sampling(points, n_samples)\n",
    "    sampled_points = points[sampled_indices]\n",
    "    \n",
    "    # Use K-means clustering to associate other points with the samples\n",
    "    kmeans = KMeans(n_clusters=n_samples, init=sampled_points, n_init=1, max_iter=100)\n",
    "    kmeans.fit(points)\n",
    "    \n",
    "    # Compute the new point positions as the mean of each cluster\n",
    "    new_points = np.array([points[kmeans.labels_ == i].mean(axis=0) for i in range(n_samples)])\n",
    "    \n",
    "    return new_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading event 13779 223 11160 from celltree.root truth file\n",
    "\n",
    "f = uproot.open(\"input_files/misclustering_candidate_truth_outputs/celltree.root\")\n",
    "\n",
    "truth_df = f[\"Event\"][\"Sim\"].arrays([\"runNo\", \"subRunNo\", \"eventNo\", \"mc_pdg\", \"mc_startXYZT\", \"mc_endXYZT\"], library=\"pd\").query(\"runNo == 13779 and subRunNo == 223 and eventNo == 11160\")\n",
    "\n",
    "mc_pdgs = truth_df[\"mc_pdg\"].to_numpy()[0]\n",
    "mc_start_xyzts = truth_df[\"mc_startXYZT\"].to_numpy()[0]\n",
    "mc_end_xyzts = truth_df[\"mc_endXYZT\"].to_numpy()[0]\n",
    "celltree_truth_spacepoints = []\n",
    "for i in range(len(mc_pdgs)):\n",
    "    pdg = mc_pdgs[i]\n",
    "    if Particle.from_pdgid(pdg).charge == 0:\n",
    "        continue # neutral particle, don't care about it for the event display\n",
    "    # removing nuclei\n",
    "    if pdg > 1000000000:\n",
    "        continue # nucleus, don't care about it for the event display\n",
    "    #print(f\"adding truth spacepoint for particle {Particle.from_pdgid(pdg).name} with pdg {pdg}\")\n",
    "\n",
    "    # correcting for offset\n",
    "    start_point = mc_start_xyzts[i][:3] + np.array([3, -5, 0])\n",
    "    end_point = mc_end_xyzts[i][:3] + np.array([3, -5, 0])\n",
    "\n",
    "    distance_between_truth_points = np.linalg.norm(end_point - start_point)\n",
    "    step_size = 0.1\n",
    "    num_steps = int(distance_between_truth_points / step_size)\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        celltree_truth_spacepoints.append(start_point + i * step_size * (end_point - start_point) / distance_between_truth_points)\n",
    "\n",
    "celltree_truth_spacepoints = np.array(celltree_truth_spacepoints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af234adf0a9f4cd896096e270f15b2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/83 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the right truth event!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[165.6, 108.2, 754.4],\n",
       "       [169.5, 106.1, 748.4],\n",
       "       [169.4, 101.5, 746.3],\n",
       "       ...,\n",
       "       [230.6,  65.4, 610.4],\n",
       "       [230.6,  65.4, 610.4],\n",
       "       [230.6,  65.4, 610.4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading event 13779 223 11160 from json truth file\n",
    "\n",
    "for dir in tqdm(os.listdir(\"input_files/misclustering_candidate_truth_outputs/bee/data/\")):\n",
    "    json_file = f\"input_files/misclustering_candidate_truth_outputs/bee/data/{dir}/{dir}-truthDepo.json\"\n",
    "\n",
    "    with open(json_file, \"r\") as f:\n",
    "        truth_data = json.load(f)\n",
    "\n",
    "    run = int(truth_data[\"runNo\"])\n",
    "    subrun = int(truth_data[\"subRunNo\"])\n",
    "    event = int(truth_data[\"eventNo\"])\n",
    "    \n",
    "    if run == 13779 and subrun == 223 and event == 11160:\n",
    "        print(\"found the right truth event!\")\n",
    "        break\n",
    "\n",
    "\n",
    "truth_spacepoints = np.column_stack((truth_data[\"x\"], truth_data[\"y\"], truth_data[\"z\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9757c6824a154c41a9edd9a34db8a970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found the right reco event!\n"
     ]
    }
   ],
   "source": [
    "# loading event 13779 223 11160 from reco file\n",
    "\n",
    "reco_dfs = []\n",
    "\n",
    "for file in tqdm(os.listdir(\"input_files/misclustering_candidate_nue_files\")):\n",
    "    if not file.endswith(\".root\"):\n",
    "        continue\n",
    "\n",
    "    f = uproot.open(f\"input_files/misclustering_candidate_nue_files/{file}\")\n",
    "\n",
    "    rse_df = f[\"Trun\"].arrays([\"runNo\", \"subRunNo\", \"eventNo\"], library=\"pd\")\n",
    "\n",
    "    if rse_df[\"runNo\"].iloc[0] == 13779 and rse_df[\"subRunNo\"].iloc[0] == 223 and rse_df[\"eventNo\"].iloc[0] == 11160:\n",
    "        print(\"found the right reco event!\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsampling cosmic spacepoints...done\n"
     ]
    }
   ],
   "source": [
    "track_shower_spacepoints_df = f[\"T_rec\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "nu_trajectory_spacepoints_blob_df = f[\"T_rec_charge_blob\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "cosmic_spacepoints_df = f[\"T_cluster\"].arrays([\"x\", \"y\", \"z\", \"q\"], library=\"pd\")\n",
    "\n",
    "cosmic_spacepoints_xyz = np.column_stack((cosmic_spacepoints_df[\"x\"], cosmic_spacepoints_df[\"y\"], cosmic_spacepoints_df[\"z\"]))\n",
    "print(\"downsampling cosmic spacepoints...\", end=\"\")\n",
    "downsampled_cosmic_spacepoints = fps_clustering_downsample(cosmic_spacepoints_xyz, 5000)\n",
    "print(\"done\")\n",
    "\n",
    "downsampled_cosmic_spacepoints_df = pd.DataFrame(downsampled_cosmic_spacepoints, columns=[\"x\", \"y\", \"z\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'scene'}]])\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=celltree_truth_spacepoints[:, 2],\n",
    "    y=celltree_truth_spacepoints[:, 0],\n",
    "    z=celltree_truth_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='blue', opacity=0.8),\n",
    "    name='celltree.root Truth Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=truth_spacepoints[:, 2],\n",
    "    y=truth_spacepoints[:, 0],\n",
    "    z=truth_spacepoints[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=2, color='orange', opacity=0.8),\n",
    "    name='BEE Truth Spacepoints'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=nu_trajectory_spacepoints_blob_df[\"z\"],\n",
    "    y=nu_trajectory_spacepoints_blob_df[\"x\"],\n",
    "    z=nu_trajectory_spacepoints_blob_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color=nu_trajectory_spacepoints_blob_df[\"q\"],\n",
    "        colorscale='Jet',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Neutrino Cluster Spacepoints'\n",
    "))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=cosmic_spacepoints_df[\"z\"],\n",
    "    y=cosmic_spacepoints_df[\"x\"],\n",
    "    z=cosmic_spacepoints_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=1,\n",
    "        color='black',\n",
    "        opacity=0.5\n",
    "    ),\n",
    "    name='Cosmic Spacepoints'\n",
    "))\n",
    "\"\"\"\n",
    "\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=downsampled_cosmic_spacepoints_df[\"z\"],\n",
    "    y=downsampled_cosmic_spacepoints_df[\"x\"],\n",
    "    z=downsampled_cosmic_spacepoints_df[\"y\"],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='red',\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    name='Downsampled Cosmic Spacepoints'\n",
    "))\n",
    "\n",
    "tpc_min_x = -1.\n",
    "tpc_max_x = 254.3\n",
    "tpc_min_y = -115.\n",
    "tpc_max_y = 117.\n",
    "tpc_min_z = 0.6\n",
    "tpc_max_z = 1036.4\n",
    "\n",
    "# First do the layout without camera settings\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title='z',\n",
    "        yaxis_title='x',\n",
    "        zaxis_title='y',\n",
    "        aspectmode=\"auto\",\n",
    "        aspectratio=dict(\n",
    "            x=(tpc_max_z - tpc_min_z),\n",
    "            y=(tpc_max_x - tpc_min_x),\n",
    "            z=(tpc_max_y - tpc_min_y)\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            range=[tpc_min_z, tpc_max_z],\n",
    "            autorange=False\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            range=[tpc_min_x, tpc_max_x],\n",
    "            autorange=False\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            range=[tpc_min_y, tpc_max_y],\n",
    "            autorange=False\n",
    "        )\n",
    "    ),\n",
    "    width=2000,\n",
    "    height=1000,\n",
    "    autosize=False\n",
    ")\n",
    "\n",
    "fig.show(renderer=\"browser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
